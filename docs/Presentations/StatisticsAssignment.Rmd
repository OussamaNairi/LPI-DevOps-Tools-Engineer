---
title: "StatisticsProblems"
author: "Matt"
date: "1/31/2019"
output: 
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)
```

# Sampling distributions

```{r}

hist(rnorm(n=100000,mean=0,sd=1))

mean(rnorm(n=100000,mean=0,sd=1))
sd(rnorm(n=100000,mean=0,sd=1))

# 1 sample mean
#n=10
save_means <-c()
for(i in 1:10000){
save_means[i]<-mean(rnorm(n=10,mean=0,sd=1))
}

# replicate

replicate(1000,mean(rnorm(n=10,mean=0,sd=1)))

mean(replicate(100000,sd(rnorm(n=10,mean=0,sd=1))))

hist(save_means)

SEM <- 1/sqrt(10)
SEM

sd(save_means)

```



## Null distribution of mean differences

If you take two random samples from the same distribution they can be different because of random sampling. This question asks you to construct a null-distribution using simulation.

1. Assume your samples come from a normal distribution with mean =0, sd =1. (use `rnorm`)
2. Assume sample size for each sample is n =10 (e.g., `rnorm(10,0,1)`)
3. Create the null-distribution: Run a simulation 10,000 times that finds the difference between means of sample A and B. You should have a vector of 10,000 difference scores
4. Assume an alpha criteria of p<.05 for a directional test.  What is the critical value for a positive mean difference? In other words, how large must a positive mean difference be in order to occur less than 5% of the time under the null?
5. Assume an alpha criteria of p<.05 for a non-directional test. What is the critical value for the absolute value of the mean difference. In other words, how large must the absolute value of the mean difference be in order to occur less than 5% of the time under the null?

```{r}
A <- rnorm(10,0,1)
B <- rnorm(10,0,1)
MD <- mean(A)-mean(B)
MD

mean_differences <- replicate(100000,
                              mean(rnorm(10,0,1))-mean(rnorm(10,0,1)))
sort(mean_differences)[95000]

sort(mean_differences)[2500]
sort(mean_differences)[97500]

hist(mean_differences)

```


## t-distribution

Show that the properties of a simulated t-distribution are the same as the properties of the analytic t-distribution. Assume df = 9.

1. For example, what are the probabilities of t(9) >= .5, 1, 1.5, 2, and 2.5? These p-values can be obtained using the `pt()` function. 

2. Create a simulated t-distribution for the null hypothesis with df=9. Here, the model situation involves taking samples of size n=10 from a normal distribution. The t-value is computed for each sample (sample mean - 0)/SEM. The process is repeated 10,000 times, and each t-value is saved. The resulting 10,000 t-values are the simulated t-distribution. 

3. Using the simulated t-distribution, find the probability of t(9) >= .5, 1, 1.5, 2, and 2.5

4. Compare the two sets of probabilities to show that the difference is small. What happens to the difference if the simulation is repeated fewer times (e.g., 100) vs. more times (e.g., 100,000)

```{r}
# your code here

real_ps <-pt(q=c(.5,1,1.5,2,2.5),df=9)

t_s <- replicate(10000,t.test(rnorm(10,0,1),mu=0)$statistic)
hist(t_s)

sim_ps <- c(length(t_s[t_s < .5])/10000,
length(t_s[t_s < 1])/10000,
length(t_s[t_s < 1.5])/10000,
length(t_s[t_s < 2])/10000,
length(t_s[t_s < 2.5])/10000)

real_ps
sim_ps

t_s <- replicate(100,t.test(rnorm(10,0,1),mu=0)$statistic)
hist(t_s)

sim_ps <- c(length(t_s[t_s < .5])/100,
length(t_s[t_s < 1])/100,
length(t_s[t_s < 1.5])/100,
length(t_s[t_s < 2])/100,
length(t_s[t_s < 2.5])/100)

real_ps
sim_ps

real_ps-sim_ps

sum(abs(real_ps-sim_ps))

```


## Correlation

Sample A and Sample B both have 10 observations randomly sampled from the same normal distribution with mean = 0, and sd =1. The expected correlation between A and B is 0, because both samples are taken randomly. 

1. Generate the distribution of correlations (Pearson r values) that could be obtained by chance (simulate 10,000 times)

2. Find the critical value such that the absolute value of the correlation occurs less than 5% of the time by chance.

3. Find the critical value when the sample-size is increased to 100

```{r}
hist(replicate(100000,cor(rnorm(100,0,1),rnorm(100,0,1))))

sim_rs<-replicate(100000,cor(rnorm(100,0,1),rnorm(100,0,1)))

sort(abs(sim_rs))[95000]

```

## F-values

There are three groups of different subjects. The means for each subject in each group are below. Calculate the F-value for the main effect of group.

```{r}
A <- c(1,2,3,4)
B <- c(3,4,5,6)
C <- c(5,6,7,8)

conds<- rep(c("A","B","C"),each=4)
DV <- c(A,B,C)
df <- data.frame(conds,DV)
summary(aov(DV~conds,df))

```

## F simulation

Assume that there are three groups of different subjects. Each group has four subjects. The subject means for all subjects are sampled randomly from  normal distribution with mean =0 and sd =1.

1. Run a simulation 10,000 times to construct the simulated F-distribution. On each run, sample new numbers into the three groups, then compute F and save it.

2. Using the simulated F-distribution, what is the critical value of F for alpha set at, p<.05

3. Compare your answer from above to the answer obtained using `qf`, that can compute the critical value directly.

```{r}

run_anova <- function(){
A <- rnorm(4,0,1)
B <- rnorm(4,0,1)
C <- rnorm(4,0,1)

conds<- rep(c("A","B","C"),each=4)
DV <- c(A,B,C)
df <- data.frame(conds,DV)
sum_out <- summary(aov(DV~conds,df))
return(sum_out[[1]]$`F value`[1])
}

save_fs <- replicate(10000,run_anova())
hist(save_fs)

sort(save_fs)[9500]

qf(.95,2,9)


```


